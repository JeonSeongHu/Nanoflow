{
    "model": {
        "architectures": [
            "LlamaForCausalLM"
        ],
        "attention_bias": false,
        "attention_dropout": 0.0,
        "bos_token_id": 128000,
        "eos_token_id": 128009,
        "hidden_act": "silu",
        "hidden_size": 4096,
        "initializer_range": 0.02,
        "intermediate_size": 14336,
        "max_position_embeddings": 8192,
        "model_type": "llama",
        "num_attention_heads": 32,
        "num_hidden_layers": 4,
        "num_key_value_heads": 8,
        "pretraining_tp": 1,
        "rms_norm_eps": 1e-05,
        "rope_scaling": null,
        "rope_theta": 500000.0,
        "tie_word_embeddings": false,
        "torch_dtype": "bfloat16",
        "transformers_version": "4.40.0.dev0",
        "use_cache": true,
        "vocab_size": 128256
    },
    "model_configs": {
        "gpu_num": 1,
        "run_layer": 32,
        "allocate_kv_data_batch": 480,
        "frame_page_size": 16,
        "max_batch_size": 2048,
        "gpu_mem": 68719476736,
        "page_mem_size": 32768
    },
    "pipeline_configs": {
        "gemm_op_tag": [
    	"128_128_32_64_64_32_1_5_RowMajor_RowMajor_RowMajor",
        "128_128_32_64_64_32_2_5_RowMajor_RowMajor_RowMajor",
        "128_128_32_64_64_32_1_5_RowMajor_RowMajor_RowMajor",
        "128_128_32_64_64_32_2_5_RowMajor_RowMajor_RowMajor",
        "128_128_32_64_64_32_3_5_RowMajor_RowMajor_RowMajor",
        "128_128_32_64_64_32_3_5_RowMajor_RowMajor_RowMajor",
		"128_256_32_64_64_32_1_3_RowMajor_RowMajor_RowMajor"
        ],
        "global_batch_size": 1024,
        "nanobatch_1_size": 384,
        "kqv1_size": 384,
        "kqv3_size": 640
    },
    "serve_configs": {
        "model": "meta-llama/Meta-Llama-3-8B-Instruct",
        "actual_gpu_num": 1,
        "weight_path": "./nanoflow_weight_8B/",
        "hf_path": "../../../hf/hub/models--meta-llama--Meta-Llama-3-8B-Instruct/snapshots/e1945c40cd546c78e41f1151f4db032b271faeaa",
        "pipeline_type": "NON_OVERLAP_LOCAL"
    }
  }
     