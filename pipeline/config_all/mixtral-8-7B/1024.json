{
    "model": {
        "architectures": [
          "MixtralForCausalLM"
        ],
        "attention_dropout": 0.0,
        "bos_token_id": 1,
        "eos_token_id": 2,
        "hidden_act": "silu",
        "hidden_size": 4096,
        "initializer_range": 0.02,
        "intermediate_size": 14336,
        "max_position_embeddings": 32768,
        "model_type": "mixtral",
        "num_attention_heads": 32,
        "num_experts_per_tok": 2,
        "num_hidden_layers": 32,
        "num_key_value_heads": 8,
        "num_local_experts": 8,
        "output_router_logits": false,
        "rms_norm_eps": 1e-05,
        "rope_theta": 1000000.0,
        "router_aux_loss_coef": 0.02,
        "sliding_window": null,
        "tie_word_embeddings": false,
        "torch_dtype": "bfloat16",
        "transformers_version": "4.36.0.dev0",
        "use_cache": true,
        "vocab_size": 32000
      },
    "model_configs": {
        "gpu_num": 8,
        "run_layer": 32,
        "allocate_kv_data_batch": 3072,
        "frame_page_size": 16,
        "max_batch_size": 6144,
        "gpu_mem": 68719476736,
        "page_mem_size": 32768
    },
    "pipeline_configs": {
        "gemm_op_tag": [
    	"128_128_32_64_64_32_1_5_RowMajor_RowMajor_RowMajor",
        "128_128_32_64_64_32_2_5_RowMajor_RowMajor_RowMajor",
        "128_128_32_64_64_32_1_5_RowMajor_RowMajor_RowMajor",
        "128_128_32_64_64_32_2_5_RowMajor_RowMajor_RowMajor",
        "128_128_32_64_64_32_3_5_RowMajor_RowMajor_RowMajor",
        "128_128_32_64_64_32_3_5_RowMajor_RowMajor_RowMajor",
		"128_256_32_64_64_32_1_3_RowMajor_RowMajor_RowMajor"
        ],
        "global_batch_size": 4096,
        "nanobatch_1_size": 2048,
        "kqv1_size": 1024,
        "kqv3_size": 1024
    },
    "serve_configs": {
        "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "actual_gpu_num": 8,
        "weight_path": "./nanoflow_weight_mixtral_8-7B/",
        "hf_path": "../../../hf/hub/models--mistralai--Mixtral-8x7B-Instruct-v0.1/snapshots/41bd4c9e7e4fb318ca40e721131d4933966c2cc1",
        "pipeline_type": "PLLM"
    }
  }
     