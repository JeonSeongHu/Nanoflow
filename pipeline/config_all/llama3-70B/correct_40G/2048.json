{
    "model": {
        "architectures": [
        "LlamaForCausalLM"
        ],
        "attention_bias": false,
        "attention_dropout": 0.0,
        "bos_token_id": 128000,
        "eos_token_id": 128009,
        "hidden_act": "silu",
        "hidden_size": 8192,
        "initializer_range": 0.02,
        "intermediate_size": 28672,
        "max_position_embeddings": 8192,
        "model_type": "llama",
        "num_attention_heads": 64,
        "num_hidden_layers": 80,
        "num_key_value_heads": 8,
        "pretraining_tp": 1,
        "rms_norm_eps": 1e-05,
        "rope_scaling": null,
        "rope_theta": 500000.0,
        "tie_word_embeddings": false,
        "torch_dtype": "bfloat16",
        "transformers_version": "4.40.0.dev0",
        "use_cache": true,
        "vocab_size": 128256
    },
    "model_configs": {
        "gpu_num": 8,
        "run_layer": 80,
        "allocate_kv_data_batch": 400,
        "frame_page_size": 16,
        "max_batch_size": 2048,
        "gpu_mem": 68719476736,
        "page_mem_size": 32768
    },
    "pipeline_configs": {
        "gemm_op_tag": [
            "128_128_32_64_64_32_3_5_RowMajor_RowMajor_RowMajor",
            "128_128_32_64_64_32_1_4_RowMajor_RowMajor_RowMajor",
            "128_128_32_64_64_32_1_5_RowMajor_RowMajor_RowMajor",
            "128_128_32_64_64_32_1_4_RowMajor_RowMajor_RowMajor",
            "128_64_64_64_32_64_2_3_RowMajor_RowMajor_RowMajor",
            "128_128_32_64_64_32_2_5_RowMajor_RowMajor_RowMajor",
            "128_128_32_64_64_32_1_5_RowMajor_RowMajor_RowMajor",
            "128_64_64_64_32_64_2_3_RowMajor_RowMajor_RowMajor",
            "128_256_32_64_64_32_2_3_RowMajor_RowMajor_RowMajor"
            ],
        "global_batch_size": 2048,
        "nanobatch_1_size": 640,
        "kqv1_size": 256,
        "kqv3_size": 768
    },
    "serve_configs": {
        "model": "meta-llama/Meta-Llama-3-70B-Instruct",
        "actual_gpu_num": 8,
        "weight_path": "./nanoflow_weight_70B_3/",
        "hf_path": "../../../hf/hub/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/1480bb72e06591eb87b0ebe2c8853127f9697bae",
        "pipeline_type": "PLLM"
    }
  }
     